{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad38304",
   "metadata": {},
   "source": [
    "# isntall libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e4b9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mattie\\miniconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mattie\\miniconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: keras in c:\\users\\mattie\\miniconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\mattie\\miniconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: pydot in c:\\users\\mattie\\miniconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: rich in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: h5py in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mattie\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 307.7/307.7 kB 18.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.0 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install libs\n",
    "%pip install numpy matplotlib keras tensorflow pydot\n",
    "%pip install -qq keras-cv\n",
    "%pip install -qq wandb\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d5422",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3af2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow import data as tf_data\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import random\n",
    "from array import array\n",
    "from IPython.display import display, Markdown\n",
    "import triangle_gen\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befe5d1",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.00000000e+00 2.55031632e+00 2.30000000e+01 2.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 3.74122827e+00 2.00000000e+01 1.13000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 4.66865109e+00 1.70000000e+01 1.37000000e+02\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 7.94085642e+00 7.70000000e+01 2.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 1.33540118e+00 2.60000000e+01 5.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 9.03303063e-01 5.00000000e+01 7.20000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 2.33344746e-01 1.20000000e+01 5.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 2.73090717e+00 8.70000000e+01 4.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 1.71675867e+00 2.60000000e+01 2.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.29429235e+00 1.50000000e+01 7.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 5.15038075e-01 3.10000000e+01 5.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 8.79256940e-01 1.70000000e+01 6.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.90472339e+00 7.20000000e+01 2.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.13095074e+00 1.30000000e+01 7.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 6.17899817e+00 2.70000000e+01 1.17000000e+02\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 4.94765073e+00 7.40000000e+01 5.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [6.00000000e+00 5.67463111e+00 6.60000000e+01 9.00000000e+00\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 5.27680322e+00 7.10000000e+01 8.80000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 9.95907099e+00 7.60000000e+01 6.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 9.72579302e-01 2.70000000e+01 8.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 4.79194906e+00 1.10000000e+01 1.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 8.86867233e+00 8.00000000e+01 1.20000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 4.79008070e+00 5.50000000e+01 1.05000000e+02\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 9.69350983e+00 8.70000000e+01 2.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 7.45418040e+00 8.60000000e+01 5.20000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 9.57280561e-01 7.00000000e+01 9.00000000e+00\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.14408998e+01 5.90000000e+01 9.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 7.60210136e+00 2.00000000e+01 1.47000000e+02\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.46471474e+00 4.70000000e+01 4.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 3.85460258e+00 7.00000000e+01 6.30000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 4.67930067e+00 6.90000000e+01 1.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 4.62422866e-02 2.00000000e+00 4.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 3.89348855e+00 6.90000000e+01 6.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [6.00000000e+00 5.32722061e-01 5.00000000e+00 7.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 1.06985612e+00 8.00000000e+01 3.30000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 3.47680336e+01 8.90000000e+01 7.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 2.16703190e+00 3.20000000e+01 4.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 7.00853559e-01 3.60000000e+01 8.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 6.61761856e+00 5.50000000e+01 4.30000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 6.12909688e+00 1.70000000e+01 1.52000000e+02\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 7.87219374e+00 7.90000000e+01 7.00000000e+00\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 8.80466940e+00 7.80000000e+01 1.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.33765771e+01 3.70000000e+01 1.30000000e+02\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.56277742e+00 4.80000000e+01 2.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 1.42863600e+01 4.90000000e+01 1.06000000e+02\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 6.31219488e+00 4.20000000e+01 8.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 6.97564737e-01 8.00000000e+00 8.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 8.82797221e+00 4.30000000e+01 1.19000000e+02\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.97765723e+01 4.90000000e+01 1.20000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 7.13103598e+00 7.20000000e+01 3.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 5.03350276e+00 3.40000000e+01 5.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 9.31180966e+00 8.80000000e+01 1.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 2.18697505e+02 5.80000000e+01 1.20000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 8.11643778e+00 7.40000000e+01 5.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 2.14729488e+00 4.00000000e+00 1.59000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 3.43596983e+00 2.90000000e+01 7.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 1.21192221e+01 5.60000000e+01 8.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 8.46702489e-01 1.40000000e+01 1.07000000e+02\n",
      "  5.40000000e+01]\n",
      " [6.00000000e+00 8.76238341e-01 3.00000000e+00 1.56000000e+02\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 3.49378273e-01 4.00000000e+00 1.23000000e+02\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 3.89985595e+00 7.70000000e+01 1.10000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 8.21205258e-01 6.00000000e+00 1.11000000e+02\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 4.42619858e+00 1.50000000e+01 2.00000000e+00\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 1.04707053e+00 6.00000000e+00 4.70000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 8.16745143e+00 5.60000000e+01 1.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.84804206e+00 6.70000000e+01 2.80000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 4.41784744e+00 2.70000000e+01 1.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [1.00000000e+00 5.76311828e-01 3.40000000e+01 4.20000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 7.96955758e+00 8.50000000e+01 6.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.19294160e+00 4.00000000e+00 1.30000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 7.47124467e+00 8.90000000e+01 4.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 5.47354839e+00 6.30000000e+01 9.80000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 7.31611141e-01 2.00000000e+00 1.67000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 6.58748636e+00 6.70000000e+01 3.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 9.34921811e+00 8.30000000e+01 4.90000000e+01\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 8.55036779e+00 5.00000000e+01 1.09000000e+02\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 4.39816759e+00 8.90000000e+01 4.80000000e+01\n",
      "  5.40000000e+01]\n",
      " [6.00000000e+00 3.79899300e-01 1.00000000e+00 1.63000000e+02\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 1.74685896e+01 2.70000000e+01 1.41000000e+02\n",
      "  5.40000000e+01]\n",
      " [4.00000000e+00 2.41645544e+00 3.70000000e+01 5.80000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 1.35555836e+01 4.50000000e+01 1.07000000e+02\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 4.76894814e-01 6.00000000e+00 2.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 4.88309836e+00 3.50000000e+01 7.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 8.65028859e-01 4.00000000e+00 1.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 1.60307391e+01 2.30000000e+01 1.50000000e+02\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 8.86888560e+00 6.60000000e+01 9.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 5.29972537e+00 4.00000000e+01 3.60000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 2.16162961e+01 4.40000000e+01 1.23000000e+02\n",
      "  5.40000000e+01]\n",
      " [5.00000000e+00 6.62927862e+00 4.00000000e+01 1.11000000e+02\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 5.74473556e+01 8.80000000e+01 8.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.61956807e+00 3.90000000e+01 9.00000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 5.11358502e+00 3.20000000e+01 2.40000000e+01\n",
      "  5.40000000e+01]\n",
      " [8.00000000e+00 6.65400470e-01 4.00000000e+00 1.19000000e+02\n",
      "  5.40000000e+01]\n",
      " [2.00000000e+00 1.50774388e+01 5.20000000e+01 1.22000000e+02\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 4.98422940e+00 2.60000000e+01 1.20000000e+01\n",
      "  5.40000000e+01]\n",
      " [3.00000000e+00 1.25279000e+00 9.00000000e+00 1.30000000e+01\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 4.97351260e+00 1.80000000e+01 1.28000000e+02\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 5.81222301e+00 1.40000000e+01 8.00000000e+00\n",
      "  5.40000000e+01]\n",
      " [9.00000000e+00 1.14098755e+01 6.80000000e+01 6.50000000e+01\n",
      "  5.40000000e+01]\n",
      " [7.00000000e+00 7.70941243e+00 3.00000000e+01 1.23000000e+02\n",
      "  5.40000000e+01]]\n",
      "[[2.96321254e+00 1.30000000e+02]\n",
      " [1.00690525e+01 4.70000000e+01]\n",
      " [1.08902891e+01 2.60000000e+01]\n",
      " [3.31479527e+00 7.90000000e+01]\n",
      " [2.46449216e+00 1.00000000e+02]\n",
      " [1.12146530e+00 5.80000000e+01]\n",
      " [8.72211303e-01 1.17000000e+02]\n",
      " [1.96714613e+00 4.70000000e+01]\n",
      " [1.59287094e+00 1.30000000e+02]\n",
      " [4.80704062e+00 9.10000000e+01]\n",
      " [8.57167301e-01 9.00000000e+01]\n",
      " [2.80758040e+00 9.40000000e+01]\n",
      " [7.17719509e-01 8.70000000e+01]\n",
      " [4.75363378e+00 9.60000000e+01]\n",
      " [1.21269667e+01 3.60000000e+01]\n",
      " [4.21620692e+00 5.10000000e+01]\n",
      " [9.71717253e-01 1.05000000e+02]\n",
      " [5.57745651e+00 2.10000000e+01]\n",
      " [8.97705670e+00 4.30000000e+01]\n",
      " [2.13055430e+00 6.90000000e+01]\n",
      " [4.36097481e+00 1.59000000e+02]\n",
      " [1.87234580e+00 8.80000000e+01]\n",
      " [5.64835636e+00 2.00000000e+01]\n",
      " [4.10227630e+00 6.80000000e+01]\n",
      " [5.88831796e+00 4.20000000e+01]\n",
      " [1.59362401e-01 1.01000000e+02]\n",
      " [1.31830080e+01 2.20000000e+01]\n",
      " [1.21057231e+01 1.30000000e+01]\n",
      " [1.44065397e+00 8.70000000e+01]\n",
      " [3.65489307e+00 4.70000000e+01]\n",
      " [1.46542823e+00 9.40000000e+01]\n",
      " [9.69053157e-01 1.31000000e+02]\n",
      " [3.77974826e+00 4.60000000e+01]\n",
      " [5.87552003e+00 1.01000000e+02]\n",
      " [5.91674268e-01 6.70000000e+01]\n",
      " [3.37404132e+01 1.50000000e+01]\n",
      " [2.94164112e+00 1.02000000e+02]\n",
      " [1.19072920e+00 5.70000000e+01]\n",
      " [5.50960599e+00 8.20000000e+01]\n",
      " [9.84170713e+00 1.10000000e+01]\n",
      " [9.77335487e-01 9.40000000e+01]\n",
      " [1.71754255e+00 9.10000000e+01]\n",
      " [1.70269138e+01 1.30000000e+01]\n",
      " [8.55336431e-01 1.08000000e+02]\n",
      " [1.81963116e+01 2.50000000e+01]\n",
      " [9.29011227e+00 5.80000000e+01]\n",
      " [5.00000000e+00 8.60000000e+01]\n",
      " [1.13213153e+01 1.80000000e+01]\n",
      " [2.26935162e+01 1.10000000e+01]\n",
      " [4.71865370e+00 6.90000000e+01]\n",
      " [7.37349142e+00 9.10000000e+01]\n",
      " [2.72416916e+00 7.50000000e+01]\n",
      " [2.23333554e+02 2.00000000e+00]\n",
      " [6.46811590e+00 5.60000000e+01]\n",
      " [1.10315448e+01 1.70000000e+01]\n",
      " [6.65984205e+00 8.10000000e+01]\n",
      " [1.45828135e+01 3.80000000e+01]\n",
      " [3.34697120e+00 5.90000000e+01]\n",
      " [6.80981617e+00 2.10000000e+01]\n",
      " [4.20051729e+00 5.30000000e+01]\n",
      " [7.63701208e-01 9.20000000e+01]\n",
      " [7.33447265e+00 6.30000000e+01]\n",
      " [5.96834375e-01 1.63000000e+02]\n",
      " [7.32603239e+00 1.27000000e+02]\n",
      " [1.71073435e+00 1.14000000e+02]\n",
      " [9.42529736e-01 8.50000000e+01]\n",
      " [3.16815096e+00 1.34000000e+02]\n",
      " [6.89615123e-01 1.04000000e+02]\n",
      " [7.25046230e+00 3.00000000e+01]\n",
      " [3.84700453e+00 1.63000000e+02]\n",
      " [5.63947885e+00 4.20000000e+01]\n",
      " [6.08332268e+00 1.90000000e+01]\n",
      " [4.71573269e+00 1.10000000e+01]\n",
      " [4.10473333e+00 7.80000000e+01]\n",
      " [7.10893339e+00 4.80000000e+01]\n",
      " [1.05536064e+01 2.10000000e+01]\n",
      " [3.26897337e+00 4.30000000e+01]\n",
      " [6.36426882e+00 1.60000000e+01]\n",
      " [2.42149112e+01 1.20000000e+01]\n",
      " [3.40515001e+00 8.50000000e+01]\n",
      " [1.83328310e+01 2.80000000e+01]\n",
      " [1.56041357e+00 1.54000000e+02]\n",
      " [8.22333435e+00 7.00000000e+01]\n",
      " [2.15335835e+00 1.66000000e+02]\n",
      " [2.05137726e+01 7.00000000e+00]\n",
      " [9.65502138e+00 1.80000000e+01]\n",
      " [4.84623594e+00 1.04000000e+02]\n",
      " [2.60976504e+01 1.30000000e+01]\n",
      " [9.62831994e+00 2.90000000e+01]\n",
      " [5.71674778e+01 8.00000000e+00]\n",
      " [2.57351913e+00 5.10000000e+01]\n",
      " [3.92490431e+00 1.24000000e+02]\n",
      " [8.34291547e+00 5.70000000e+01]\n",
      " [1.62261660e+01 6.00000000e+00]\n",
      " [2.36393196e+00 1.42000000e+02]\n",
      " [1.80149836e+00 1.58000000e+02]\n",
      " [1.26827375e+01 3.40000000e+01]\n",
      " [3.34366221e+00 1.58000000e+02]\n",
      " [1.11529757e+01 4.70000000e+01]\n",
      " [1.29313146e+01 2.70000000e+01]]\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattie\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2946.9482\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1501.3455 \n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 867.4103 \n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 954.6437  \n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 171.9574 \n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.7862 \n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.1390 \n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.7441 \n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.0115 \n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6753 \n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6356 \n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5270 \n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4312 \n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2175 \n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8018 \n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8046 \n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6755 \n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0183 \n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1785 \n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9203 \n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8219 \n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3478 \n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5764 \n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5682 \n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4060 \n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5702 \n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4417 \n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2650 \n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4167 \n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6284 \n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4399 \n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5790 \n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2026 \n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2779 \n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2481 \n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3888 \n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2891 \n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0942 \n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5240 \n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9964 \n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9450 \n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7842 \n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6438 \n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2488 \n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9933 \n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7778 \n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8247 \n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2570 \n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4862 \n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2279 \n",
      "MSE: 1.6213964223861694\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "score: 1.6213964223861694<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_size = 100\n",
    "triangles = []\n",
    "\n",
    "x_data_set = []\n",
    "y_data_set = []\n",
    "\n",
    "\n",
    "\n",
    "for n in range(dataset_size):\n",
    "    #two angles and two sides known\n",
    "    triangle = triangle_gen.TriangleGenerator().generate_random_triangle_via_angles(known_indices=[0,1,3,4])\n",
    "    x = (triangle.angles[0], triangle.angles[1], triangle.sides[0], triangle.sides[1], triangle.triangle_type)\n",
    "    y = (triangle.angles[2], triangle.sides[2])\n",
    "    x_data_set.append(x)\n",
    "    y_data_set.append(y)\n",
    "    \n",
    "x_data_set = np.array(x_data_set)\n",
    "y_data_set = np.array(y_data_set)\n",
    "    \n",
    "print(x_data_set)\n",
    "print(y_data_set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data_set, y_data_set, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model_1 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[5]),        # In layer\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),        # Hidden layer\n",
    "    keras.layers.Dense(128, activation=keras.activations.linear),        # Hidden layer\n",
    "    keras.layers.Dense(128, activation=keras.activations.relu),        # Hidden layer\n",
    "    keras.layers.Dense(2, activation='linear')       # Out layer\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model_1.fit(X_train, y_train, epochs=50, batch_size=8)\n",
    "\n",
    "score = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"MSE:\", score)\n",
    "\n",
    "display(Markdown(f\"MSE: {score}<br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92ebc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
